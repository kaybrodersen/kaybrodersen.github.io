<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-2L89Q0P6GR"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-2L89Q0P6GR');
    </script>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Kay H. Brodersen / Google LLC">
    <meta name="author" content="Kay H. Brodersen">
    <link rel="icon" href="./favicon.ico">

    <title>Downloads</title>

    <!-- Bootstrap core CSS -->
    <link href="./bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles -->
    <link href="starter-template.css" rel="stylesheet">
    <link href="jumbotron-narrow.css" rel="stylesheet">
    <link href="custom-extras.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body>
	<!-- Main container -->
    <div class="container">

      <!-- Header -->
  	  <div id="header">
		<h1>Kay H. Brodersen</h1>
		<!-- <p>Google</p> -->
	  </div>

      <!-- Navigation bar -->
      <nav class="navbar navbar-default">
        <div class="container">
	      <!-- ||| button -->
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
          </div>
          <!-- Navigation items -->
          <div id="navbar" class="collapse navbar-collapse">
            <ul class="nav navbar-nav"> <!-- pull-right -->
              <li><a href="./index.html">Home</a></li>
              <li><a href="./publications.html">Publications</a></li>
              <li><a href="./talks.html">Talks</a></li>
              <li class="active"><a href="#">Code</a></li>
            </ul>
          </div><!--/.nav-collapse -->
        </div>
      </nav>

      <!-- Content resides in 'row' elements with 'col' child elements -->
      <div class="row" id="content">
  	    <div class="col-md-12">

		  <h3>Code</h3>

  	      <a href="https://github.com/kaybrodersen" target="blank">
  	      	View GitHub profile<span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span>
  	      </a>
  	      <br/><br/>

		<a name="causalimpact"></a>
		<h4>CausalImpact: A new R package for estimating causal effects in time series</h4>
		<img src="img/CausalImpact_thumbnail.png" width="120" class="thumbnail" alt="CausalImpact R package" />
		<p>09/2014 &mdash; The <a href="https://google.github.io/CausalImpact/" target="blank">CausalImpact</a> R package implements an approach to estimating the causal effect of a designed intervention on a time series. For example, how many additional daily clicks were generated by an advertising campaign? Answering a question like this can be difficult when a randomized experiment is not available. The package overcomes this difficulty using a structural Bayesian time-series model to estimate how the response metric would have evolved after the intervention if the intervention had not occurred.</p>
		<a href="http://google-opensource.blogspot.com/2014/09/causalimpact-new-open-source-package.html" target="_blank"><img class="fileicon" src="fileicons/html.png">Google Open Source Blog</a><br/>
		<a href="https://google.github.io/CausalImpact/" target="_blank"><img class="fileicon" src="fileicons/html.png">Project site</a><br/>
		<a href="https://github.com/google/CausalImpact" target="_blank"><img class="fileicon" src="fileicons/html.png">GitHub repository</a><br/>
		<a href="https://google.github.io/CausalImpact/CausalImpact.html" target="_blank"><img class="fileicon" src="fileicons/file.png">Documentation</a><br/>
		<div class="horline"></div>

			<a name="laplace_vb"></a>
			<h4>An interactive comparison of the Laplace approximation and variational Bayes</h4>
			<img src="img/laplace_vb.png" width="120" class="thumbnail" alt="Laplace vs. variational Bayes" />
			<p>03/2014 &mdash; In Bayesian inference, the Laplace approximation is a simple scheme for obtaining an approximate posterior. However, it is a local approximation that is often too strong a simplification. Variational Bayesian (VB) inference generalizes the idea behind the Laplace approximation: it finds an approximate posterior that maximizes the free energy and thus minimizes the KL-divergence between approximate and true posterior. This MATLAB demo illustrates the differences between the two approximations.</p>
			<a href="downloads/VariationalBayesDemo_1.01.zip"><img class="fileicon" src="fileicons/zip.png">Download v1.01</a> (17 KB)<br/>
			<a href="talks/Brodersen_2013_03_22.pdf" target="_blank"><img class="fileicon" src="fileicons/pdf.png">Slides</a>
			<div class="horline"></div>

			<a name="micp_r"></a>
			<h4>Variational Bayesian linear regression: a MATLAB implementation</h4>
			<img src="img/vblm.png" width="120" height="119" class="thumbnail" alt="Variational linear regression" />
			<p>03/2013 &mdash; The conceptual and practical limitations of classical multiple linear regression models can be resolved naturally in a Bayesian framework. Unless based on an overly simplistic parameterization, however, exact inference in Bayesian regression models is analytically intractable. This problem can be overcome using methods for approximate inference. This MATLAB toolbox implements variational inference for a fully Bayesian multiple linear regression model, including Bayesian model selection and prediction of unseen data points on the basis of the posterior predictive density. See <a href="./talks/Brodersen_2013_03_22.pdf" target="blank">these slides</a> for the derivation.</p>
			<a href="downloads/vblm_1.02.zip"><img class="fileicon" src="fileicons/zip.png">Download v1.02</a> (360 KB)<br/>
			<a href="downloads/Readme_vblm.pdf"><img class="fileicon" src="fileicons/pdf.png">Documentation</a><br/>
			<a href="talks/Brodersen_2013_03_22.pdf" target="_blank"><img class="fileicon" src="fileicons/pdf.png">Slides</a>
			<div class="horline"></div>

			<a name="micp_r"></a>
			<h4>Variational Bayesian inference on classification performance: an R package</h4>
			<img src="img/micp_r.png" width="120" height="106" class="thumbnail" alt="Mixed-effects inference" />
			<p>01/2013 &mdash; Mixed-effects inference is critical whenever one wishes to evaluate the performance of a classification algorithm that has been trained and tested on a hierarchically structured dataset. This setting is very common in domains as varied as spam detection, brain-machine interfaces, and neuroimaging. This R package provides an efficient variational Bayesian implementation of the normal-binomial model for mixed-effects inference. The package permits inference on accuracies as well as balanced accuracies. For details, see <a href="publications/Brodersen_2013_NeuroImage.pdf" target="blank">Brodersen et al. (2013) <i>NeuroImage</i></a>.</p>
			This code is hosted on <a href="https://github.com/kaybrodersen/micp">GitHub</a>.<br/>
			<div class="horline"></div>

			<a name="micp"></a>
			<h4>Mixed-effects inference on classification performance: a MATLAB toolbox</h4>
			<img src="img/micp.jpg" width="120" height="106" class="thumbnail" alt="Mixed-effects inference" />
			<p>06/2012 &mdash; Classification algorithms are often used in a hierarchical setting, where a classifier is trained and tested on individual datasets which are themselves sampled from a group. Examples of this sort of analysis are ubiquitous and are common in domains as varied as spam detection, brain-machine interfaces, and neuroimaging. This toolbox provides answers to the questions of statistical inference that arise in all of these settings. It implements models that account for both within-subjects (fixed-effects) and between-subjects (random-effects) variance components and thus provide mixed-effects inference. The toolbox provides (i) asymptotically exact MCMC implementations as well as (ii) computationally efficient variational Bayes approximations. For details about the MCMC sampler, see <a href="publications/Brodersen_2012_JMLR.pdf" target="blank">Brodersen et al. (2012) <i>JMLR</i></a>. For details about the variational algorithms, see <a href="publications/Brodersen_2013_NeuroImage.pdf" target="blank">Brodersen et al. (2013) <i>NeuroImage</i></a>.</p>
			<a href="downloads/micp-1.05.zip"><img class="fileicon" src="fileicons/zip.png">Download v1.05</a> (40 KB)<br/>
			<a href="downloads/Readme_micp_for_MATLAB.pdf" target="blank"><img class="fileicon" src="fileicons/pdf.png">Documentation for MATLAB</a><br/>
			<div class="horline"></div>

			<a name="bb_java"></a>
			<h4>Bayesian model inversion of the beta-binomial model in Java</h4>
			<img src="img/bb.jpg" width="120" height="106" class="thumbnail" alt="Beta-binomial model" />
			<p>11/2011 &mdash; The beta-binomial model enables the performance evaluation of a classification algorithm that is used in a hierarchical context. This archive contains a Java implementation of a Metropolis-Hastings/Gibbs sampling scheme. The algorithm is asymptotically exact and about 10 times faster than an equivalent MATLAB implementation. For details about the model, see <a href="publications/Brodersen_2010b_ICPR.pdf" target="blank">Brodersen et al. (2010b) <i>ICPR</i></a>.</p>
			<a href="downloads/BetaBinomialSampler-1.0.jar"><img class="fileicon" src="fileicons/zip.png">Download v1.0</a> (13 KB)<br/>
			<div class="horline"></div>

			<a name="mvpa"></a>
			<h4>Multivariate pattern analysis (MVPA) framework</h4>
			<img src="img/mvpa.jpg" width="120" height="136" class="thumbnail" alt="MVPA framework" />
			<p>04/2011 &mdash; The MVPA framework for MATLAB provides a generic environment for the application of statistical methods to high-dimensional datasets, such as those obtained by functional magnetic resonance imaging (fMRI). The framework is highly extensible and supports tight integration with <a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/" class="muted" target="_blank">LIBSVM</a>, the <a href="http://code.google.com/p/princeton-mvpa-toolbox/" class="muted" target="_blank">Princeton MVPA toolbox</a>, and <a href="http://en.wikipedia.org/wiki/Oracle_Grid_Engine" class="muted" target="_blank">Sun Grid Engine</a> for use on high-performance compute clusters running Linux. It is published under the terms of the <a href="http://www.gnu.org/licenses/gpl.html" class="muted" target="_blank">GNU General
			Public License</a>. </p>
			<a href="downloads/MVPA-3.2-r10406.zip"><img class="fileicon" src="fileicons/zip.png">Download v3.2 (r10406)</a> (703 KB)<br/>
			<div class="horline"></div>

			<a name="balanced_accuracy"></a>
			<h4>Computing the posterior balanced accuracy</h4>
			<img src="img/balacc.jpg" width="120" height="64" class="thumbnail" alt="Posterior balanced accuracy" />
			<p>10/2010 &mdash; The average accuracy obtained on individual cross-validation folds is a problematic measure of generalization performance. First, it makes statistical inference difficult. Second, it leads to an optimistic estimate when a biased classifier is tested on an imbalanced dataset. Both problems can be overcome by replacing the conventional point estimate of accuracy by an estimate of the posterior distribution of the balanced accuracy. The archive below contains a set of MATLAB functions to estimate the posterior distribution of the balanced accuracy and compute its associated statistics. For details, see <a href="publications/Brodersen_2010b_ICPR.pdf" target="blank">Brodersen et al. (2010b) <i>ICPR</i></a>.</p>
			This code is hosted on <a href="http://www.mathworks.com/matlabcentral/fileexchange/29244" target="_blank">MATLAB Central</a>.
			<div class="horline"></div>

			<a name="pr_curve"></a>
			<h4>Estimating a smooth precision-recall curve</h4>
			<img src="img/binormal.jpg" width="120" height="108" class="thumbnail" alt="Empirical and model-based precision-recall curves" />
			<p>06/2010 &mdash; The precision-recall curve (PRC) has become a widespread conceptual tool for assessing classification performance. The curve relates the positive predictive value of a classifier to its true positive rate and provides a useful alternative to the well-known receiver operating characteristic (ROC). A smooth estimate of the PRC can be computed on the basis of a simple distributional assumption about the underlying decision values. The archive below contains a MATLAB implementation of this approach. For details, see <a href="publications/Brodersen_2010a_ICPR.pdf" target="blank">Brodersen et al. (2010a) <i>ICPR</i></a>.</p>
			This code is hosted on <a href="http://www.mathworks.com/matlabcentral/fileexchange/29250" target="_blank">MATLAB Central</a>.
			<div class="horline"></div>

			<a name="mbfc"></a>
			<h4>Dataset for model-based feature construction</h4>
			<img src="img/mbfc.jpg" width="120" height="162" class="thumbnail" alt="Model-based feature construction" />
		    <p>04/2010 &mdash; Model-based feature construction is a multivariate-decoding approach that addresses the twin challenges of feature selection and biological interpretability by (i) inverting a dynamic systems model of neurophysiological data in a trial-by-trial fashion; (ii) training and testing a discriminative classifier on a feature space derived from the trial-wise model parameter estimates; and (iii) reconstructing how informative each model parameter was in separating the cognitive states of interest. The archive below contains the somatosensory dataset used for illustrating this approach in <a href="publications/Brodersen_2011_NeuroImage.pdf" target="blank">Brodersen et al. (2011) <i>NeuroImage</i></a>.</p>
			<a href="downloads/ModelBasedFeatureConstruction-1.01.zip"><img class="fileicon" src="fileicons/zip.png">Download</a> (78 KB)
			<div class="horline"></div>

			<a name="simple_classifier"></a>
			<h4>Decoding cognitive states from fMRI: a simple example</h4>
			<img src="img/simple_classifier.jpg" width="120" height="125" class="thumbnail" alt="Simple classifier" />
			<p>02/2010 &mdash; Contemporary analysis pipelines for decoding brain states based on fMRI typically comprise thousands of lines of code. In contrast, this example illustrates the core principles behind fMRI classification in just about two screens full of MATLAB code. The example contains a fully preprocessed single-subject dataset. The first analysis performs a simple classification analysis, resulting in a classification accuracy. The second analysis creates a probabilistic map of feature importance. Updated on 12/02/2014.</p>
			<a href="downloads/SimpleClassifier-1.06.zip"><img class="fileicon" src="fileicons/zip.png">Download v1.06</a> (57 MB)
			<br/><br/>
	
  	    </div><!-- /.col -->
	  </div><!-- /.row -->
    </div><!-- /.container -->

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="./bootstrap/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="./assets/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
